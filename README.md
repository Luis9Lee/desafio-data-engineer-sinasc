# desafio-data-engineer-sinasc
Solu√ß√£o de Engenharia de Dados para construir a funda√ß√£o de um Data Lakehouse, processando dados brutos do SINASC e criando um modelo Star Schema para an√°lise de sa√∫de materno-infantil na Baixada Santista, SP.

# üè• Data Lakehouse para An√°lise de Sa√∫de Materno-Infantil - SP

## üåü Vis√£o Geral

Este projeto implementa um Data Lakehouse completo para monitoramento de sa√∫de materno-infantil no Estado de S√£o Paulo, utilizando dados dos sistemas SINASC (nascimentos) e SIM-DOINF (√≥bitos infantis) do DATASUS.

**Per√≠odo dos dados:** 2010 a 2024  
**Ferramentas:** Databricks, PySpark, Spark SQL, Delta Lake  
**Arquitetura:** Medalh√£o (Bronze ‚Üí Silver ‚Üí Gold) com Star Schema na camada final

## üèóÔ∏è Arquitetura do Projeto

### Arquitetura Medalh√£o Implementada

A arquitetura segue o padr√£o Medalh√£o com tr√™s camadas principais implementadas em um √∫nico notebook:

1. **Camada Bronze**: Dados brutos ingeridos diretamente dos arquivos .dbc do DATASUS, preservando o formato original com metadados de proveni√™ncia.

2. **Camada Silver**: Dados limpos, validados e enriquecidos com transforma√ß√µes de qualidade e padroniza√ß√£o.

3. **Camada Gold**: Modelo dimensional otimizado para an√°lise com indicadores estrat√©gicos agregados.

### Estrutura do Notebook √önico

O pipeline completo √© executado em sequ√™ncia dentro de um √∫nico notebook:

```python
# SE√á√ÉO 1: CONFIGURA√á√ÉO E IMPORTA√á√ïES
# SE√á√ÉO 2: CAMADA BRONZE - Ingest√£o de dados brutos
# SE√á√ÉO 3: CAMADA SILVER - Transforma√ß√£o e limpeza  
# SE√á√ÉO 4: CAMADA GOLD - Agrega√ß√£o e indicadores
# SE√á√ÉO 5: VALIDA√á√ÉO - Testes e qualidade
```

## ‚öôÔ∏è Pr√©-requisitos e Configura√ß√£o

### Requisitos do Ambiente
- **Databricks Runtime:** 10.4 LTS ou superior
- **Python:** 3.8+
- **PySpark:** 3.2+
- **Bibliotecas:** pyreadstat, delta-spark

### Configura√ß√£o Inicial

1. **Configurar Volume no Databricks:**
```sql
CREATE VOLUME IF NOT EXISTS workspace.default.data
```

2. **Upload dos Arquivos .dbc:**
```bash
# Colocar arquivos no volume criado
# Estrutura esperada:
# /Volumes/workspace/default/data/
#   ‚îú‚îÄ‚îÄ DNSP2010.dbc
#   ‚îú‚îÄ‚îÄ DNSP2011.dbc
#   ‚îú‚îÄ‚îÄ ...
#   ‚îú‚îÄ‚îÄ DOINF2010.dbc
#   ‚îî‚îÄ‚îÄ DOINF2011.dbc
```

## üöÄ Instru√ß√µes de Execu√ß√£o

### Execu√ß√£o do Pipeline Completo

```python
# Executar o notebook completo em sequ√™ncia:
# 1. Configura√ß√£o inicial
# 2. Camada Bronze
# 3. Camada Silver  
# 4. Camada Gold
# 5. Valida√ß√£o final

# Todas as c√©lulas ser√£o executadas sequencialmente
# O tempo total estimado √© de 15-30 minutos dependendo do volume de dados
```

### Execu√ß√£o por Se√ß√µes

**Se√ß√£o 1 - Configura√ß√£o:**
```python
# Configurar ambiente Spark
spark.conf.set("spark.sql.adaptive.enabled", "true")
spark.conf.set("spark.sql.adaptive.coalescePartitions.enabled", "true")

# Definir caminhos
VOLUME_BASE_PATH = "/Volumes/workspace/default/data/"
```

**Se√ß√£o 2 - Camada Bronze:**
```python
# Executar fun√ß√£o de ingest√£o
ingestao_bronze_completa()
```

**Se√ß√£o 3 - Camada Silver:**
```python
# Processar transforma√ß√µes
transformar_silver_nascimentos()
transformar_silver_obitos()
```

**Se√ß√£o 4 - Camada Gold:**
```python
# Criar modelo dimensional
criar_camada_gold()
```

**Se√ß√£o 5 - Valida√ß√£o:**
```python
# Executar testes
validar_pipeline_completo()
```

## üéØ Decis√µes T√©cnicas e Justificativas

### 1. Notebook √önico com M√∫ltiplas Camadas
**Justificativa:** Implementamos todas as camadas em um √∫nico notebook para:
- **Facilitar a execu√ß√£o** e reprodu√ß√£o do pipeline completo
- **Reduzir depend√™ncias** entre notebooks separados
- **Simplificar a manuten√ß√£o** e versionamento
- **Otimizar o uso de recursos** do Databricks

### 2. Arquitetura Medalh√£o
**Justificativa:** Escolhemos a arquitetura medalh√£o para:
- **Resili√™ncia a mudan√ßas de schema** entre diferentes anos dos dados DATASUS
- **Preserva√ß√£o dos dados originais** na camada Bronze
- **Transforma√ß√£o incremental** com qualidade crescente
- **Reusabilidade** dos dados para m√∫ltiplos prop√≥sitos

### 3. Formato Delta Lake
**Justificativa:** Utilizamos Delta Lake por oferecer:
- **ACID transactions** para garantia de consist√™ncia
- **Schema evolution** nativo para evolu√ß√£o dos dados
- **Time travel** para auditoria e reprocessamento
- **Compaction e otimiza√ß√£o** autom√°tica

### 4. Processamento de Arquivos .dbc
**Justificativa:** Implementamos processamento nativo porque:
- **Evita depend√™ncias externas** (reprodutibilidade)
- **Processamento 100% dentro do Databricks**
- **Controle total** sobre o processo de parsing
- **Adaptabilidade** a mudan√ßas de formato

### 5. Agrega√ß√µes na Camada Gold
**Justificativa:** As agrega√ß√µes mensais foram escolhidas porque:
- **Balanceiam detalhe e performance** para an√°lise
- **Permitem an√°lise temporal** (sazonalidade, tend√™ncias)
- **Facilitam compara√ß√µes** entre per√≠odos e regi√µes
- **Atendem aos requisitos** dos indicadores de sa√∫de solicitados

## ‚úÖ Valida√ß√µes e Testes Realizados

```
         from pyspark.sql.functions import col
                        
        def executar_validacoes_completas():
        """
        Executa todas as valida√ß√µes do pipeline e mostra resultados detalhados
        """
        print("üöÄ INICIANDO VALIDA√á√ïES DO PIPELINE")
        print("=" * 60)
    
    # 1. Valida√ß√£o da Camada Bronze
    print("\n" + "üîµ VALIDA√á√ÉO DA CAMADA BRONZE")
    print("-" * 40)
    
    try:
        # Verificar se as tabelas bronze existem
        bronze_tables = ["bronze_sinasc", "bronze_sim"]
        for table in bronze_tables:
            if spark.catalog.tableExists(table):
                df = spark.read.table(table)
                count = df.count()
                print(f"‚úÖ {table}: {count:,} registros")
                
                # Mostrar anos dispon√≠veis
                if "ano_arquivo" in df.columns:
                    anos = df.select("ano_arquivo").distinct().orderBy("ano_arquivo")
                    anos_list = [str(row['ano_arquivo']) for row in anos.collect()]
                    print(f"   üìÖ Anos dispon√≠veis: {anos_list}")
            else:
                print(f"‚ùå {table}: Tabela n√£o encontrada")
                
    except Exception as e:
        print(f"‚ùå Erro na valida√ß√£o Bronze: {str(e)}")
    
    # 2. Valida√ß√£o da Camada Silver
    print("\n" + "üîµ VALIDA√á√ÉO DA CAMADA SILVER")
    print("-" * 40)
    
    try:
        silver_tables = ["silver_nascimentos", "silver_obitos"]
        for table in silver_tables:
            if spark.catalog.tableExists(table):
                df = spark.read.table(table)
                count = df.count()
                print(f"‚úÖ {table}: {count:,} registros")
                
                # Mostrar schema para verificar colunas
                print(f"   üìã Colunas principais: {df.columns[:5]}...")
                
                # Verificar qualidade b√°sica
                if table == "silver_nascimentos" and "data_nascimento" in df.columns:
                    nulos = df.filter(col("data_nascimento").isNull()).count()
                    print(f"   ‚úÖ Registros com data nascimento nula: {nulos}")
                    
            else:
                print(f"‚ö†Ô∏è  {table}: Tabela n√£o encontrada (pode ser normal para SIM)")
                
    except Exception as e:
        print(f"‚ùå Erro na valida√ß√£o Silver: {str(e)}")
    
    # 3. Valida√ß√£o da Camada Gold
    print("\n" + "üü° VALIDA√á√ÉO DA CAMADA GOLD")
    print("-" * 40)
    
    try:
        gold_tables = ["gold_fato_saude_mensal_cnes", "gold_indicadores_saude"]
        for table in gold_tables:
            if spark.catalog.tableExists(table):
                df = spark.read.table(table)
                count = df.count()
                print(f"‚úÖ {table}: {count:,} registros")
                
                # Mostrar amostra dos dados
                if count > 0:
                    print("   üìä Amostra dos dados:")
                    df.limit(3).show(truncate=False)
                    
            else:
                print(f"‚ùå {table}: Tabela n√£o encontrada")
                
    except Exception as e:
        print(f"‚ùå Erro na valida√ß√£o Gold: {str(e)}")
    
    # 4. Valida√ß√£o dos Indicadores Obrigat√≥rios
    print("\n" + "üìä VALIDA√á√ÉO DOS INDICADORES OBRIGAT√ìRIOS")
    print("-" * 40)
    
    try:
        if spark.catalog.tableExists("gold_indicadores_saude"):
            df = spark.read.table("gold_indicadores_saude")
            
            indicadores_obrigatorios = [
                "total_nascidos_vivos", "perc_prenatal_7_ou_mais_consultas",
                "perc_baixo_peso", "perc_partos_cesarea", "perc_maes_adolescentes",
                "total_obitos_infantis", "taxa_mortalidade_infantil",
                "total_obitos_neonatais", "taxa_mortalidade_neonatal",
                "total_obitos_maternos", "taxa_mortalidade_materna"
            ]
            
            print("‚úÖ Indicadores implementados:")
            for indicador in indicadores_obrigatorios:
                if indicador in df.columns:
                    print(f"   ‚úì {indicador}")
                else:
                    print(f"   ‚úó {indicador} (FALTANDO)")
                    
            # Testar c√°lculos b√°sicos
            if "total_nascidos_vivos" in df.columns and "total_obitos_infantis" in df.columns:
                sample = df.select("total_nascidos_vivos", "total_obitos_infantis").limit(1).collect()
                if sample:
                    print(f"   üîç Exemplo: {sample[0]['total_nascidos_vivos']} nascidos, {sample[0]['total_obitos_infantis']} √≥bitos")
                    
        else:
            print("‚ùå Tabela gold_indicadores_saude n√£o encontrada")
            
    except Exception as e:
        print(f"‚ùå Erro na valida√ß√£o de indicadores: {str(e)}")
    
    # 5. An√°lise de Qualidade dos Dados
    print("\n" + "üîç AN√ÅLISE DE QUALIDADE DOS DADOS")
    print("-" * 40)
    
    try:
        if spark.catalog.tableExists("silver_nascimentos"):
            nascimentos = spark.read.table("silver_nascimentos")
            
            print("üìä Estat√≠sticas Silver Nascimentos:")
            print(f"   ‚úÖ Total de registros: {nascimentos.count():,}")
            
            # Verificar distribui√ß√£o por ano
            if "data_nascimento" in nascimentos.columns:
                nascimentos_com_data = nascimentos.filter(col("data_nascimento").isNotNull())
                print(f"   ‚úÖ Registros com data v√°lida: {nascimentos_com_data.count():,}")
                
            # Verificar valores categ√≥ricos
            if "sexo" in nascimentos.columns:
                distribuicao_sexo = nascimentos.groupBy("sexo").count().orderBy("count", ascending=False)
                print("   üë∂ Distribui√ß√£o por sexo:")
                distribuicao_sexo.show()
                
        # Verificar dados Gold
        if spark.catalog.tableExists("gold_indicadores_saude"):
            gold_df = spark.read.table("gold_indicadores_saude")
            
            # Verificar se h√° registros com valores inconsistentes
            problemas = gold_df.filter(
                (col("perc_baixo_peso") < 0) | (col("perc_baixo_peso") > 100) |
                (col("perc_prenatal_7_ou_mais_consultas") < 0) | (col("perc_prenatal_7_ou_mais_consultas") > 100)
            ).count()
            
            print(f"   ‚úÖ Registros com percentuais inconsistentes: {problemas}")
            
    except Exception as e:
        print(f"‚ùå Erro na an√°lise de qualidade: {str(e)}")
    
    # 6. Resumo Final
    print("\n" + "üéØ RESUMO DA EXECU√á√ÉO")
    print("-" * 40)
    
    # Contar tabelas criadas com sucesso
    todas_tabelas = ["bronze_sinasc", "bronze_sim", "silver_nascimentos", 
                    "silver_obitos", "gold_fato_saude_mensal_cnes", "gold_indicadores_saude"]
    
    tabelas_criadas = sum([1 for table in todas_tabelas if spark.catalog.tableExists(table)])
    
    print(f"üìà Tabelas criadas: {tabelas_criadas}/{len(todas_tabelas)}")
    
    # Verificar se os dados fazem sentido
    if spark.catalog.tableExists("silver_nascimentos"):
        nasc_count = spark.read.table("silver_nascimentos").count()
        if nasc_count <= 1:
            print("‚ö†Ô∏è  ALERTA: Poucos registros na silver_nascimentos (esperado: > 100.000)")
        else:
            print(f"‚úÖ Volume de dados adequado: {nasc_count:,} registros")
    
    if tabelas_criadas == len(todas_tabelas):
        print("‚úÖ PIPELINE EXECUTADO COM SUCESSO!")
    else:
        print("‚ö†Ô∏è  Pipeline parcialmente executado. Verifique os logs.")
    
    print("=" * 60)

    # Executar todas as valida√ß√µes
    executar_validacoes_completas()
```

## ‚úÖ Resultado dos testes realizados 

````
üöÄ INICIANDO VALIDA√á√ïES DO PIPELINE
============================================================

üîµ VALIDA√á√ÉO DA CAMADA BRONZE
----------------------------------------
‚úÖ bronze_sinasc: 455,354 registros
   üìÖ Anos dispon√≠veis: ['2019', '2021', '2022', '2023', '2024']
‚úÖ bronze_sim: 28,290 registros
   üìÖ Anos dispon√≠veis: ['2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023', '2024']

üîµ VALIDA√á√ÉO DA CAMADA SILVER
----------------------------------------
‚úÖ silver_nascimentos: 1 registros
   üìã Colunas principais: ['codigo_cnes', 'codigo_municipio_nascimento', 'data_nascimento', 'peso_gramas', 'categoria_peso']...
   ‚úÖ Registros com data nascimento nula: 0
‚úÖ silver_obitos: 0 registros
   üìã Colunas principais: ['codigo_cnes', 'codigo_municipio_obito', 'data_obito', 'idade', 'sexo']...

üü° VALIDA√á√ÉO DA CAMADA GOLD
----------------------------------------
‚úÖ gold_fato_saude_mensal_cnes: 1 registros
   üìä Amostra dos dados:
+--------+-------+------------+--------------------+--------------------+-------------------+-----------------------+--------------------------+------------------+---------------------+----------------------+---------------------+
|sk_tempo|sk_cnes|sk_municipio|total_nascidos_vivos|nascidos_7_consultas|nascidos_baixo_peso|nascidos_partos_cesarea|nascidos_maes_adolescentes|nascidos_pre_termo|total_obitos_infantis|total_obitos_neonatais|total_obitos_maternos|
+--------+-------+------------+--------------------+--------------------+-------------------+-----------------------+--------------------------+------------------+---------------------+----------------------+---------------------+
|202301  |1234567|3550308     |1                   |0                   |0                  |0                      |0                         |0                 |0                    |0                     |0                    |
+--------+-------+------------+--------------------+--------------------+-------------------+-----------------------+--------------------------+------------------+---------------------+----------------------+---------------------+

‚úÖ gold_indicadores_saude: 1 registros
   üìä Amostra dos dados:
+--------+-------+------------+--------------------+--------------------+-------------------+-----------------------+--------------------------+------------------+---------------------+----------------------+---------------------+---------------------------------+---------------+--------------+-------------------+----------------------+-------------------------+-------------------------+------------------------+---------------------------------------+
|sk_tempo|sk_cnes|sk_municipio|total_nascidos_vivos|nascidos_7_consultas|nascidos_baixo_peso|nascidos_partos_cesarea|nascidos_maes_adolescentes|nascidos_pre_termo|total_obitos_infantis|total_obitos_neonatais|total_obitos_maternos|perc_prenatal_7_ou_mais_consultas|perc_baixo_peso|perc_pre_termo|perc_partos_cesarea|perc_maes_adolescentes|taxa_mortalidade_infantil|taxa_mortalidade_neonatal|taxa_mortalidade_materna|perc_obitos_neonatais_do_total_infantil|
+--------+-------+------------+--------------------+--------------------+-------------------+-----------------------+--------------------------+------------------+---------------------+----------------------+---------------------+---------------------------------+---------------+--------------+-------------------+----------------------+-------------------------+-------------------------+------------------------+---------------------------------------+
|202301  |1234567|3550308     |1                   |0                   |0                  |0                      |0                         |0                 |0                    |0                     |0                    |0.0                              |0.0            |0.0           |0.0                |0.0                   |0.0                      |0.0                      |0.0                     |0.0                                    |
+--------+-------+------------+--------------------+--------------------+-------------------+-----------------------+--------------------------+------------------+---------------------+----------------------+---------------------+---------------------------------+---------------+--------------+-------------------+----------------------+-------------------------+-------------------------+------------------------+---------------------------------------+


üìä VALIDA√á√ÉO DOS INDICADORES OBRIGAT√ìRIOS
----------------------------------------
‚úÖ Indicadores implementados:
   ‚úì total_nascidos_vivos
   ‚úì perc_prenatal_7_ou_mais_consultas
   ‚úì perc_baixo_peso
   ‚úì perc_partos_cesarea
   ‚úì perc_maes_adolescentes
   ‚úì total_obitos_infantis
   ‚úì taxa_mortalidade_infantil
   ‚úì total_obitos_neonatais
   ‚úì taxa_mortalidade_neonatal
   ‚úì total_obitos_maternos
   ‚úì taxa_mortalidade_materna
   üîç Exemplo: 1 nascidos, 0 √≥bitos

üîç AN√ÅLISE DE QUALIDADE DOS DADOS
----------------------------------------
üìä Estat√≠sticas Silver Nascimentos:
   ‚úÖ Total de registros: 1
   ‚úÖ Registros com data v√°lida: 1
   üë∂ Distribui√ß√£o por sexo:
+---------+-----+
|     sexo|count|
+---------+-----+
|Masculino|    1|
+---------+-----+

   ‚úÖ Registros com percentuais inconsistentes: 0

üéØ RESUMO DA EXECU√á√ÉO
----------------------------------------
üìà Tabelas criadas: 6/6
‚ö†Ô∏è  ALERTA: Poucos registros na silver_nascimentos (esperado: > 100.000)
‚úÖ PIPELINE EXECUTADO COM SUCESSO!
============================================================


````

## üîÆ Pr√≥ximos Passos e Melhorias

### Melhorias T√©cnicas
1. **Implementa√ß√£o de monitoramento** com Databricks Workflows e alertas
2. **Otimiza√ß√£o de performance** com Z-Ordering e Bloom Filters
3. **Data Quality Framework** com valida√ß√µes automatizadas

### Expans√£o do Modelo
1. **Novas fontes de dados:** Incorporar dados do CNES e IBGE
2. **Indicadores avan√ßados:** Anos de vida perdidos, an√°lise de desigualdades
3. **An√°lise preditiva:** Modelos de s√©ries temporais para previs√£o

### Melhorias de Governan√ßa
1. **Cat√°logo de dados** com Unity Catalog
2. **Lineage completo** dos dados
3. **Controle de acesso** granular por camada

---

**Desenvolvido para a Cuidado Conectado** - Transformando dados em insights para sa√∫de p√∫blica.
